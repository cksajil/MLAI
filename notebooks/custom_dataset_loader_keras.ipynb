{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN1lgW7I9s1gubZtU7lZeJt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np"],"metadata":{"id":"XxHZXT4jj_9K"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z5WvVjijjtQu"},"outputs":[],"source":["class CustomDatasetLoader(tf.keras.utils.Sequence):\n","    def __init__(self, data_paths, labels, batch_size, shuffle=True):\n","        self.data_paths = data_paths\n","        self.labels = labels\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        return int(np.floor(len(self.data_paths) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n","        data_paths_temp = [self.data_paths[k] for k in indexes]\n","        labels_temp = [self.labels[k] for k in indexes]\n","\n","        X, y = self.__data_generation(data_paths_temp, labels_temp)\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.data_paths))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, data_paths_temp, labels_temp):\n","        X = np.empty((self.batch_size, *self.image_size, self.channels))\n","        y = np.empty((self.batch_size), dtype=int)\n","\n","        for i, data_path in enumerate(data_paths_temp):\n","            image = tf.keras.preprocessing.image.load_img(data_path, target_size=self.image_size)\n","            image = tf.keras.preprocessing.image.img_to_array(image)\n","            image = image / 255.0  # Normalize pixel values\n","            X[i,] = image\n","            y[i] = labels_temp[i]\n","        return X, tf.keras.utils.to_categorical(y, num_classes=self.num_classes)"]},{"cell_type":"code","source":["data_paths = [\"path/to/image1.jpg\", \"path/to/image2.png\", ...]\n","labels = [0, 1, ...]\n","image_size = (64, 64)\n","channels = 3\n","num_classes = 2\n","batch_size = 32"],"metadata":{"id":"VnGTjgVqkPDx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_custom_dataset_loader = CustomDatasetLoader(data_paths, labels, batch_size)\n","my_custom_dataset_loader.image_size = image_size\n","my_custom_dataset_loader.channels = channels\n","my_custom_dataset_loader.num_classes = num_classes"],"metadata":{"id":"m4iZO9KVkWJO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model.fit(my_custom_dataset_loader, epochs=10)"],"metadata":{"id":"s5NEXt-ukY2H"},"execution_count":null,"outputs":[]}]}